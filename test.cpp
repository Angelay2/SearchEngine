/*
1. 一个搜索

像百度, 搜狗,谷歌遮掩的搜索引擎, 是进行"全网搜索"
整个互联网上的内容都会被这些搜索引擎给搜索出来
这些搜索引擎管理的数据量级是非常大的,  客观条件(服务器)不具备, 技术实力不够, 想实现全网搜索,还是比较困难的
做一个站内搜索(只在某个网站内部进行搜索---->B站,知乎..)
站内搜索只考虑该网站内部的网页信息即可, 处理的数量就大大减小了
实现站内搜索的基本原理和全网搜索是类似的

以Boost文档页面为例来演示这个过程
C++标准库的功能是非常弱的, Boost就是一个很好的补充(标准备胎), 组件多(C++标准库里好多都是Boost引用过来的)但是boost的官方文档上没有搜索功能(不方便)

实现一个Boost文档的搜索引擎
1. 为啥要做: Boost官方文档没有搜索功能
2. 实现一个全网搜索成本较高 实现站内搜索相对容易
3. Boost文档提供了两个版本, 离线版本(下载), 在线版本(浏览器访问)
	基于离线版本分析文档页面的内容, 为搜索功能提供支持
	在线点击搜索结果的标题的时候就能跳转到在线版本的文档上
如果网站内容无法直接下载, 就必须使用爬虫来抓取页面到本地
 在线版本文档和离线版本的文档是一一对应的(正因为有这样的对应关系, 就可以通过分析离线文档的方式, 去进一步的搜索在线文档内容

*/

/*
如何实现搜索呢?
本质就在于找到用户输入的查询次都在哪些文档(html)中出现过?

方法有很多: 
简单粗暴: 遍历每个文件, 然后在每个文件中进行字符串搜索_-----> 效率会比较低,(旧百度,搜索完成的时候, 会提示, 在0.1s之内为您找到xxx个相关网页
实现搜索, 核心的数据结构, "倒排索引"-----> 搜索引擎中最核心的数据结构!!!!

例如只有两个html文档, 根据编号, 就能直到对应的文档内容
01  乔布斯发布了苹果手机
02  乔布斯买了4斤苹果

构建倒排索引时需要先针对文档内容进行分词!!!(就是把一句话切成若干个词, )
文档内容        文档id
乔布斯			01 02
发布				01
苹果				01 02
手机				01 
买				02
四斤				02
倒排索引的核心, 根据此映射到该词在哪些文档中国包含着
根据文档id --> 文档内容  (正排索引)
根据文档内容---> 文档id  (倒排索引)

倒排索引这样的映射关系, 就可以使用hash表来进行查找 (hash的查找效率很高 ---时间复杂度O(1))

光有倒排索引还不够, 整体项目的模块划分
1. 预处理模块: 读取原始的html文档内容, 进行预处理操作(解析处一些重要信息, 文档标题, 文档的URL, 文档的正文(去除原理的html标签, 只保留正文)
	把预处理完毕的结果整理成行文本文件, 以备后面进一步的使用
2. 索引模块: 输入内容就是上面的文本内容, 读取这些内容, 在内存中构造处正排索引和倒排索引, 并且提供一些API供其他的模块进行调用(从内容中构造出来,以备后面搜索)
3. 搜索模块: 完成一次搜索的整个过程
	a) 先针对查询词进行分词(查询的词可能比较长)  ----->分词
	b) 根据刚才的分词结果, 查找倒排索引, 找到那些文档是和当前的查询词相关的(此处暂时不考虑近义词) ------> 触发
	c) 把刚才搜索到的文档按照一定规则进行排序, 相关性越高的文档排的越排前(相关性是一个很大的话题, 暂时只使用一种简单粗暴的方式来完成, 相关性是一个指标, 还有一个重要的指标(是否给钱---竞价排名)谁给的钱多往前排)广告后面第一个往往就是相关性最高的  ------>排序
	d) 刚才触发出来是结果和排序的结果都是包含了一些文档id, 而我们希望网页上显示的是标题,url,描述..
		就需要拿着文档id, 去查正排索引, 把结果包装起来返回给发起请求的客户端 ------>包装/构造结果
4. 服务器模块(http服务器, 给外部提供服务)
*/

/*
1. 分词的实现
C++开源的分词库, 使用cppjieba, 先下载到本地
vim这个东西实在是太老了, 功能也跟不上时代了 
code-server: 网页版本的VScode(可以吧code-server部署到云服务器上, 通过浏览器就可以打开, 随时进行开发,(突破图片

makefile中必须通过 -I(大写i)来指定结巴分词的头文件的

1. 把

枚举
遍历目录得使用递归
*/
